{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import all packages\n",
    "\n",
    "import requests\n",
    "import ConfigParser\n",
    "from TwitterAPI import TwitterAPI\n",
    "import sys\n",
    "from collections import Counter\n",
    "import pickle\n",
    "import re\n",
    "from itertools import product\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from collections import defaultdict\n",
    "from scipy.sparse import lil_matrix\n",
    "\n",
    "class sampleClass14:\n",
    "\n",
    "    def __init__(self):\n",
    "            print \n",
    "\n",
    "    def get_census_names(self):\n",
    "        males = requests.get('http://www2.census.gov/topics/genealogy/1990surnames/dist.male.first').text.split('\\n')\n",
    "        females = requests.get('http://www2.census.gov/topics/genealogy/1990surnames/dist.female.first').text.split('\\n')\n",
    "        males_pct = dict([(m.split()[0].lower(), float(m.split()[1])) for m in males if m])\n",
    "        females_pct = dict([(f.split()[0].lower(), float(f.split()[1])) for f in females if f])\n",
    "        male_names = set([m for m in males_pct if m not in females_pct or males_pct[m] > females_pct[m]])\n",
    "        female_names = set([f for f in females_pct if f not in males_pct or females_pct[f] > males_pct[f]]) \n",
    "        return male_names, female_names\n",
    "    \n",
    "    def get_first_name(self,tweet):\n",
    "        if 'user' in tweet and 'name' in tweet['user']:\n",
    "            parts = tweet['user']['name'].split()\n",
    "            if len(parts) > 0:\n",
    "                return parts[0].lower()\n",
    "            \n",
    "    \n",
    "    def make_feature_matrix(self,tokens_list, vocabulary,len_tweets):\n",
    "        X = lil_matrix((len_tweets, len(vocabulary)))\n",
    "        for i, tokens in enumerate(tokens_list):\n",
    "            for token in tokens:\n",
    "                j = vocabulary[token]\n",
    "                X[i,j] += 1\n",
    "        return X.tocsr()\n",
    "    \n",
    "    def tokenize(self,string, lowercase, keep_punctuation, prefix,collapse_urls, collapse_mentions,collapse_stop_words):\n",
    "        if not string:\n",
    "            return []\n",
    "        if lowercase:\n",
    "            string = string.lower()\n",
    "        tokens = []\n",
    "        if collapse_urls:\n",
    "            string = re.sub('http\\S+', 'THIS_IS_A_URL', string)\n",
    "        if collapse_mentions:\n",
    "            string = re.sub('@\\S+', 'THIS_IS_A_MENTION', string)\n",
    "        if keep_punctuation:\n",
    "            tokens = string.split()\n",
    "        else:\n",
    "            tokens = re.sub('\\W+', ' ', string).split()\n",
    "        if collapse_stop_words:\n",
    "            tokens = list(set(tokens) - set(stopwords.words('english')))\n",
    "        if prefix:\n",
    "            tokens = ['%s%s' % (prefix, t) for t in tokens]\n",
    "        return tokens\n",
    "    \n",
    "    def tweet2tokens(self,tweet, use_descr=True, lowercase=True,keep_punctuation=True, descr_prefix='d=',\n",
    "                 collapse_urls=True, collapse_mentions=True, use_text=True,collapse_stop_words = True):\n",
    "        tokens = []\n",
    "        if use_text:\n",
    "            tokens.extend(self.tokenize(tweet['text'], lowercase, keep_punctuation, None,collapse_urls, collapse_mentions,collapse_stop_words))\n",
    "        if use_descr:\n",
    "            tokens.extend(self.tokenize(tweet['user']['description'], lowercase,keep_punctuation, descr_prefix,collapse_urls, collapse_mentions,collapse_stop_words))\n",
    "        return tokens\n",
    "    \n",
    "    def make_vocabulary(self,tokens_list):\n",
    "        vocabulary = defaultdict(lambda: len(vocabulary)) # Similar to vocabulary = defaultdict(int)\n",
    "        for tokens in tokens_list:\n",
    "            for token in tokens:\n",
    "                vocabulary[token]\n",
    "        print '%d unique terms in vocabulary' % len(vocabulary)\n",
    "        return vocabulary\n",
    "    \n",
    "    def get_gender(self,tweet, male_names, female_names):\n",
    "        name = self.get_first_name(tweet)\n",
    "        if name in female_names:\n",
    "            return 1\n",
    "        elif name in male_names:\n",
    "            return 0\n",
    "        else:\n",
    "            return -1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
